{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac890b9c-cd22-43e1-9772-f050a4105018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T01:27:39.340046Z",
     "iopub.status.busy": "2024-08-03T01:27:39.339045Z",
     "iopub.status.idle": "2024-08-03T01:27:43.722620Z",
     "shell.execute_reply": "2024-08-03T01:27:43.722620Z",
     "shell.execute_reply.started": "2024-08-03T01:27:39.340046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Bounding Box in Web Mercator: (12523442.714243276, 0.0, 17532819.799940586, 7514065.628545966)\n",
      "E:/OneDrive_PSU/OneDrive - The Pennsylvania State University/Research_doc/LLM-Find/Downloaded_Data/Japan_image.tif\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from osgeo import gdal\n",
    "import os\n",
    "from pyproj import Transformer\n",
    "import rasterio\n",
    "\n",
    "\n",
    "def download_data():\n",
    "    # Define the target area for which to download the data\n",
    "    place = 'Japan'\n",
    "\n",
    "    # Get the boundary of Japan\n",
    "    # get the first return's bounding box\n",
    "    url = f\"https://nominatim.openstreetmap.org/search?q={place}&format=geojson\"\n",
    "    response = requests.get(url, headers={\"User-Agent\":\"LLM-Find/gladcolor@gmail.com\"})\n",
    "    minx, miny, maxx, maxy = response.json()['features'][0]['bbox']\n",
    "\n",
    "    # extend the boundary for a point or to small:\n",
    "    if abs(maxx - minx) < 0.000001:  # note unit is degree\n",
    "         ext = 0.00005\n",
    "         maxx = maxx + ext\n",
    "         minx = minx - ext\n",
    "         maxy = maxy + ext\n",
    "         miny = miny - ext \n",
    "        \n",
    "    # Set the zoom level\n",
    "    z = 4\n",
    "    n = 2 ** z\n",
    "\n",
    "    # Calculate the tiling scheme boundaries\n",
    "    tile_min_col = int((minx + 180.0) / 360.0 * n)\n",
    "    tile_max_col = int((maxx + 180.0) / 360.0 * n)\n",
    "    tile_min_row = int((1.0 - np.log(np.tan(np.radians(maxy)) + 1 / np.cos(np.radians(maxy))) / np.pi) / 2.0 * n)\n",
    "    tile_max_row = int((1.0 - np.log(np.tan(np.radians(miny)) + 1 / np.cos(np.radians(miny))) / np.pi) / 2.0 * n)\n",
    "\n",
    "    # Create directory to store individual tile images\n",
    "    save_dir = \"tiles\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Download tiles\n",
    "    for row in range(tile_min_row, tile_max_row + 1):\n",
    "        for col in range(tile_min_col, tile_max_col + 1):\n",
    "            url = f\"https://services.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{row}/{col}\"\n",
    "            response = requests.get(url)\n",
    "            tile_path = os.path.join(save_dir, f\"{z}-{row}-{col}.jpg\")\n",
    "            with open(tile_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "    # Stitch the tiles to create a mosaic image\n",
    "    cols = tile_max_col - tile_min_col + 1\n",
    "    rows = tile_max_row - tile_min_row + 1\n",
    "    tile_width, tile_height = Image.open(os.path.join(save_dir, f\"{z}-{tile_min_row}-{tile_min_col}.jpg\")).size\n",
    "    mosaic = Image.new('RGB', (cols * tile_width, rows * tile_height))\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            tile_path = os.path.join(save_dir, f\"{z}-{tile_min_row + row}-{tile_min_col + col}.jpg\")\n",
    "            tile = Image.open(tile_path)\n",
    "            mosaic.paste(tile, (col * tile_width, row * tile_height))\n",
    "\n",
    "    # Save the mosaic image as a TIFF file\n",
    "    image_array = np.array(mosaic)\n",
    "\n",
    "        # Calculate the actual geographic bounds of the mosaic\n",
    "    def tile_to_lonlat(col, row, zoom):\n",
    "        n = 2.0 ** zoom\n",
    "        lon_deg = col / n * 360.0 - 180.0\n",
    "        lat_rad = np.arctan(np.sinh(np.pi * (1 - 2 * row / n)))\n",
    "        lat_deg = np.degrees(lat_rad)\n",
    "        return lon_deg, lat_deg\n",
    "\n",
    "    actual_min_lon, actual_max_lat = tile_to_lonlat(tile_min_col, tile_min_row, z)\n",
    "    actual_max_lon, actual_min_lat = tile_to_lonlat(tile_max_col + 1, tile_max_row + 1, z)\n",
    "\n",
    "       # Convert geographic bounds to Web Mercator\n",
    "    transformer = Transformer.from_crs(\"epsg:4326\", \"epsg:3857\", always_xy=True)\n",
    "    actual_min_x, actual_min_y = transformer.transform(actual_min_lon, actual_min_lat)\n",
    "    actual_max_x, actual_max_y = transformer.transform(actual_max_lon, actual_max_lat)\n",
    "\n",
    "    # Set the bounding box for Web Mercator\n",
    "    actual_bounding_box_mercator = actual_min_x, actual_min_y, actual_max_x, actual_max_y\n",
    "    print(\"Actual Bounding Box in Web Mercator:\", actual_bounding_box_mercator)\n",
    "    \n",
    "    transform = from_bounds(*actual_bounding_box_mercator, width=mosaic.width, height=mosaic.height)\n",
    "\n",
    "    mosaic_path = \"E:/OneDrive_PSU/OneDrive - The Pennsylvania State University/Research_doc/LLM-Find/Downloaded_Data/Japan_image.tif\"\n",
    "    crs = {'init': 'epsg:3857'}\n",
    "\n",
    "    # Save the image as a GeoTIFF using rasterio\n",
    "    print(mosaic_path)\n",
    "    with rasterio.open(\n",
    "        mosaic_path,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=image_array.shape[0],\n",
    "        width=image_array.shape[1],\n",
    "        count=image_array.shape[2],  # Number of channels (e.g., 3 for RGB)\n",
    "        dtype=image_array.dtype,\n",
    "        crs=crs,\n",
    "        transform=transform\n",
    "    ) as dst:\n",
    "        # Write each channel separately\n",
    "        for i in range(1, image_array.shape[2] + 1):\n",
    "            print(i)\n",
    "            dst.write(image_array[:, :, i - 1], i)\n",
    " \n",
    "    # Clean up the individual tile images (optional)\n",
    "    for file in os.listdir(save_dir):\n",
    "        os.remove(os.path.join(save_dir, file))\n",
    "    os.rmdir(save_dir)\n",
    "\n",
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfba34b1-68e1-4ad4-a267-dd4a5fd593eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T20:57:20.716056Z",
     "iopub.status.busy": "2024-08-02T20:57:20.716056Z",
     "iopub.status.idle": "2024-08-02T20:57:20.719942Z",
     "shell.execute_reply": "2024-08-02T20:57:20.719942Z",
     "shell.execute_reply.started": "2024-08-02T20:57:20.716056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Affine(0.0006835937500000028, 0.0, 27.82,\n",
       "       0.0, -0.0031250000000000167, 87.73)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array.shape\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ba153a9-2331-4dc3-b807-a3c7ded110d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T21:07:12.305584Z",
     "iopub.status.busy": "2024-08-02T21:07:12.305584Z",
     "iopub.status.idle": "2024-08-02T21:07:12.321538Z",
     "shell.execute_reply": "2024-08-02T21:07:12.321538Z",
     "shell.execute_reply.started": "2024-08-02T21:07:12.305584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "# Load the image using PIL\n",
    "pil_image = Image.open(r\"E:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM-Find\\Python_code\\Downloaded_Data\\Everest_DOM.tif\")\n",
    "\n",
    "# Convert the PIL image to a NumPy array\n",
    "image_array = np.array(pil_image)\n",
    "\n",
    "# Define the bounding box (left, bottom, right, top)\n",
    "# Example coordinates (in desired CRS units, e.g., meters or degrees)\n",
    "bounding_box = 86.73, 27.82, 87.13, 28.17# from_bounds(west, south, east, north, width, height)\n",
    "\n",
    "# Define the transform for the GeoTIFF based on the bounding box\n",
    "transform = from_bounds(*bounding_box, width=pil_image.width, height=pil_image.height)\n",
    "\n",
    "# Define the CRS (coordinate reference system) for the output GeoTIFF\n",
    "# Example using WGS 84 (EPSG:4326), but change as needed for your data\n",
    "crs = {'init': 'epsg:4326'}\n",
    "\n",
    "# Save the image as a GeoTIFF using rasterio\n",
    "with rasterio.open(\n",
    "    r'E:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM-Find\\Python_code\\Downloaded_Data\\output_image.tif',\n",
    "    'w',\n",
    "    driver='GTiff',\n",
    "    height=image_array.shape[0],\n",
    "    width=image_array.shape[1],\n",
    "    count=image_array.shape[2],  # Number of channels (e.g., 3 for RGB)\n",
    "    dtype=image_array.dtype,\n",
    "    crs=crs,\n",
    "    transform=transform\n",
    ") as dst:\n",
    "    # Write each channel separately\n",
    "    for i in range(1, image_array.shape[2] + 1):\n",
    "        print(i)\n",
    "        dst.write(image_array[:, :, i - 1], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e3e507f-52bc-4103-9662-68eeab77fc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## The following code is to download the railway network in Wuhan, Hubei, China.\n",
      "# Import necessary libraries\n",
      "import geopandas as gpd\n",
      "import requests\n",
      "import json\n",
      "import osmnx as ox\n",
      "\n",
      "def download_data():\n",
      "    # Define the area for Wuhan, Hubei, China\n",
      "    place_name = \"Wuhan, Hubei, China\"\n",
      "\n",
      "    # Get the bounding box of Wuhan using OSMnx\n",
      "    gdf = ox.geocode_to_gdf(place_name)\n",
      "    west, south, east, north = gdf.unary_union.bounds\n",
      "\n",
      "    # Define Overpass API query to get railway network in the bounding box\n",
      "    overpass_url = \"https://overpass-api.de/api/interpreter\"\n",
      "    overpass_query = f \"\"\"    [out:json];\n",
      "    (\n",
      "        way[\"railway\"]({south},{west},{north},{east});\n",
      "        relation[\"railway\"]({south},{west},{north},{east});\n",
      "    );\n",
      "    out geom;\n",
      "      \"\"\"    # Send request to Overpass API\n",
      "    response = requests.get(overpass_url, params={'data': overpass_query})\n",
      "    response.raise_for_status()  # Automatically raises an error for bad status codes\n",
      "\n",
      "    # Parse the JSON response\n",
      "    data = response.json()\n",
      "\n",
      "    # Extract elements with their geometries\n",
      "    features = []\n",
      "    for element in data['elements']:\n",
      "        if 'geometry' in element:\n",
      "            points = [(point['lon'], point['lat']) for point in element['geometry']]\n",
      "            # Convert all property values to str\n",
      "            properties = {\n",
      "                key: ', '.join(map(str, value)) if isinstance(value, list) else str(value)\n",
      "                for key, value in element.items() if key != 'geometry'\n",
      "            }\n",
      "\n",
      "            if element['type'] == 'way':\n",
      "                features.append({\n",
      "                    'type': 'Feature',\n",
      "                    'geometry': {'type': 'LineString', 'coordinates': points},\n",
      "                    'properties': properties\n",
      "                })\n",
      "            elif element['type'] == 'relation':\n",
      "                for member in element['members']:\n",
      "                    if member['type'] == 'way' and 'geometry' in member:\n",
      "                        points = [(point['lon'], point['lat']) for point in member['geometry']]\n",
      "                        properties = {\n",
      "                            key: ', '.join(map(str, value)) if isinstance(value, list) else str(value)\n",
      "                            for key, value in element.items() if key != 'geometry'\n",
      "                        }\n",
      "                        features.append({\n",
      "                            'type': 'Feature',\n",
      "                            'geometry': {'type': 'LineString', 'coordinates': points},\n",
      "                            'properties': properties\n",
      "                        })\n",
      "\n",
      "    # Create a GeoDataFrame\n",
      "    gdf_railway = gpd.GeoDataFrame.from_features(features, crs='EPSG:4326')\n",
      "\n",
      "    # Save to GeoPackage\n",
      "    output_file = r\"E:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM-Find\\Downloaded_Data\\Wuhan_Railway_network.gpkg\"\n",
      "    gdf_railway.to_file(output_file, layer='railway_network', driver='GPKG')\n",
      "\n",
      "# Execute the function\n",
      "download_data()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import toml\n",
    "\n",
    "handbook_file = r'D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM-Find\\Python_code\\Handbooks\\OpenStreetMap.toml'\n",
    "\n",
    "handbook = toml.load(handbook_file)\n",
    "print(handbook['code_example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7444f6f-04dd-487c-9a27-55f05a6f2e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb198a-42a4-4314-8efe-c5a1d67a4c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "ox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
